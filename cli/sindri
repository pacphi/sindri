#!/bin/bash
# Sindri CLI - Main entry point

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Detect environment and source common functions
if [[ -f "/docker/lib/common.sh" ]]; then
    # Running inside container
    source /docker/lib/common.sh
    BASE_DIR="/docker"
else
    # Running on host
    BASE_DIR="$(dirname "$SCRIPT_DIR")"
    source "$BASE_DIR/docker/lib/common.sh"
fi

show_version() {
    local version_file
    local version

    # Try to find VERSION file (co-located with sindri CLI)
    if [[ -f "$SCRIPT_DIR/VERSION" ]]; then
        version_file="$SCRIPT_DIR/VERSION"
    elif [[ -f "/docker/cli/VERSION" ]]; then
        version_file="/docker/cli/VERSION"
    fi

    if [[ -n "$version_file" && -f "$version_file" ]]; then
        version=$(tr -d '[:space:]' < "$version_file")
    else
        version="unknown"
    fi

    # Check if we're on a tagged release commit
    if command -v git &>/dev/null && [[ -d "$SCRIPT_DIR/../.git" || -d "$BASE_DIR/.git" ]]; then
        local git_dir="${SCRIPT_DIR}/.."
        [[ -d "$BASE_DIR/.git" ]] && git_dir="$BASE_DIR"

        # Get current commit SHA
        local sha
        sha=$(git -C "$git_dir" rev-parse --short HEAD 2>/dev/null)

        # Check if current commit is tagged with a version tag
        local tag
        tag=$(git -C "$git_dir" describe --exact-match --tags HEAD 2>/dev/null | grep -E '^v?[0-9]+\.[0-9]+\.[0-9]+' || true)

        # If not on a tagged release, append dev suffix
        if [[ -z "$tag" && -n "$sha" ]]; then
            version="${version}-dev+${sha}"
        fi
    fi

    echo "sindri version $version"
}

show_help() {
    cat << 'EOH'
sindri - Cloud Development Forge

USAGE:
    sindri <command> [options]

COMMANDS:
    deploy [--provider <name>] [--rebuild] [--config <file>]
                                 Deploy to provider (docker, fly, devpod)
    plan [--config <file>]       Show deployment plan
    destroy [--provider <name>] [--force] [--config <file>]
                                 Destroy deployment
    connect [--config <file>]    Connect to deployed instance
    status [--config <file>]     Show deployment status
    test [--config <file>] [--suite <name>]
                                 Run test suite on deployed instance

    profiles list                List available profiles
    profiles show <name>         Show profile details

    config init                  Initialize sindri.yaml
    config validate [--config <file>]
                                 Validate configuration against schema

    backup [--profile <name>] [--output <path>]
                                 Backup workspace (profiles: user-data, standard, full)
    restore <file> [--mode <name>]
                                 Restore from backup (modes: safe, merge, full)
    backup list                  List backups on instance

OPTIONS:
    -h, --help                   Show this help
    -V, --version                Show version information
    -c, --config <file>          Use specific config file (default: sindri.yaml)
    -v, --verbose                Verbose output

DEPLOY/DESTROY OPTIONS:
    -p, --provider <name>        Override provider from config (docker, fly, devpod)
    -r, --rebuild                Force rebuild of Docker image (deploy only)
    -f, --force                  Skip confirmation prompt (destroy only)

EXAMPLES:
    sindri config init
    sindri deploy --provider docker
    sindri deploy --provider fly
    sindri deploy --provider fly --rebuild  # Force rebuild on Fly.io
    sindri deploy --provider devpod
    sindri deploy --config examples/fly/minimal.sindri.yaml
    sindri connect
    sindri destroy --provider docker
    sindri destroy --force
    sindri test --config examples/fly/minimal.sindri.yaml --suite smoke

    # Backup and restore
    sindri backup                            # Standard backup
    sindri backup --profile user-data        # User data only (migration)
    sindri backup --output s3://bucket/path  # Backup to S3
    sindri restore ./backup.tar.gz           # Safe restore
    sindri restore ./backup.tar.gz --dry-run # Preview restore

    # Local Kubernetes cluster management
    sindri k8s create --provider kind
    sindri k8s config
    sindri k8s destroy --force

LOCAL KUBERNETES:
    k8s create [--provider <kind|k3d>] [--name <name>] [--config <file>]
                                 Create local Kubernetes cluster
    k8s config [--name <name>]   Show kubeconfig context for DevPod integration
    k8s destroy [--name <name>] [--force]
                                 Destroy local Kubernetes cluster
    k8s list                     List all local Kubernetes clusters
    k8s status [--name <name>]   Show cluster status
EOH
}

# Initialize configuration
config_init() {
    if [[ -f "sindri.yaml" ]]; then
        print_warning "sindri.yaml already exists"
        read -p "Overwrite? (y/N) " -n 1 -r
        echo
        [[ ! $REPLY =~ ^[Yy]$ ]] && return 0
    fi

    cat > sindri.yaml << 'EOYAML'
# Sindri Configuration
# ====================
# Reference files:
#   In repo:      docker/lib/profiles.yaml, docker/lib/registry.yaml
#   In container: /docker/lib/profiles.yaml, /docker/lib/registry.yaml
#
# Key references:
#   - profiles.yaml    - Extension profiles (minimal, fullstack, ai-dev, etc.)
#   - registry.yaml    - All available extensions
#   - categories.yaml  - Extension categories
#   - vm-sizes.yaml    - VM size mappings per provider
#
# Documentation: docs/CONFIGURATION.md, docs/SCHEMA.md
# Examples: examples/ directory (organized by provider)

version: "1.0"
name: my-sindri-dev

# =============================================================================
# DEPLOYMENT
# =============================================================================
deployment:
  provider: docker  # Options: docker, fly, devpod

  resources:
    memory: 2GB     # RAM allocation (e.g., 1GB, 2GB, 4GB, 8GB)
    cpus: 2         # Number of CPUs (1-8)

    # GPU support (optional) - see vm-sizes.yaml for provider-specific options
    # gpu:
    #   enabled: true
    #   type: nvidia          # nvidia or amd
    #   count: 1              # Number of GPUs (1-8)
    #   tier: gpu-medium      # gpu-small, gpu-medium, gpu-large, gpu-xlarge
    #   memory: 16GB          # Minimum GPU memory

  volumes:
    workspace:
      path: /alt/home/developer
      size: 10GB    # Persistent volume size

# =============================================================================
# EXTENSIONS
# =============================================================================
# Three options for configuring extensions:
#
# Option 1: Use a profile (recommended for quick setup)
# Option 2: List specific extensions with 'active' (mutually exclusive with profile)
# Option 3: Use a profile + additional extensions

extensions:
  # Option 1: Use a predefined profile
  profile: fullstack
  # Available profiles:
  #   Standard:   minimal, fullstack, ai-dev, anthropic-dev,
  #               systems, enterprise, devops, mobile
  #   VisionFlow: visionflow-core, visionflow-data-scientist,
  #               visionflow-creative, visionflow-full
  # See: docker/lib/profiles.yaml for contents of each profile

  # Option 2: List specific extensions (mutually exclusive with profile)
  # active:
  #   - nodejs
  #   - python
  #   - docker
  #   - ai-toolkit
  # See: docker/lib/registry.yaml for all available extensions

  # Option 3: Add extensions on top of a profile
  # additional:
  #   - rust
  #   - golang
  #   - infra-tools

  # Auto-install extensions on container startup (default: true)
  # Set to false for manual control or CI testing where tests install explicitly
  autoInstall: true

# =============================================================================
# SECRETS
# =============================================================================
# Set via provider-specific mechanisms:
#   - Docker: environment variables or .env file
#   - Fly.io: flyctl secrets set KEY=value -a app-name
#   - DevPod: environment variables

secrets:
  # SSH key-based authentication (recommended for Fly.io)
  # Uses fromFile to read your public key automatically - no manual export needed
  - name: AUTHORIZED_KEYS
    source: env
    fromFile: ~/.ssh/id_ed25519.pub

  # Claude Code
  - name: ANTHROPIC_API_KEY
    source: env

  # GitHub integration
  - name: GITHUB_TOKEN
    source: env
  - name: GIT_USER_NAME
    source: env
  - name: GIT_USER_EMAIL
    source: env

  # AI Tools (optional) - see docs/SECRETS_MANAGEMENT.md for details
  # - name: OPENROUTER_API_KEY    # OpenRouter multi-provider AI gateway (claudish)
  #   source: env
  # - name: GOOGLE_GEMINI_API_KEY # Google Gemini API (vf-gemini-flow, ai-toolkit)
  #   source: env
  # - name: PERPLEXITY_API_KEY    # Perplexity AI research (vf-perplexity, vf-ontology-enrich)
  #   source: env
  # - name: DEEPSEEK_API_KEY      # DeepSeek AI reasoning (vf-deepseek-reasoning)
  #   source: env
  # - name: ZAI_ANTHROPIC_API_KEY # Cost-effective Claude wrapper (vf-zai-service)
  #   source: env
  # - name: CONTEXT7_API_KEY      # Context7 library documentation MCP (context7-mcp)
  #   source: env                 # Get key at: https://context7.com/dashboard (optional, enables higher rate limits)

  # Project Management Tools (optional)
  # - name: LINEAR_API_KEY        # Linear.app issue tracking (linear-mcp)
  #   source: env
  # - name: JIRA_URL              # Atlassian Jira base URL (jira-mcp)
  #   source: env                 # Example: https://mycompany.atlassian.net
  # - name: JIRA_USERNAME         # Atlassian account email (jira-mcp)
  #   source: env
  # - name: JIRA_API_TOKEN        # Atlassian API token (jira-mcp)
  #   source: env                 # Create at: https://id.atlassian.com/manage-profile/security/api-tokens

  # Infrastructure Tools (optional)
  # - name: SUPABASE_ACCESS_TOKEN # Supabase CLI authentication (supabase-cli)
  #   source: env                 # Create at: https://supabase.com/dashboard/account/tokens

  # File-based secrets (mount entire files into container)
  # - name: SSH_KEY
  #   source: file
  #   path: ~/.ssh/id_rsa
  #   mountPath: /home/developer/.ssh/id_rsa
  #   permissions: "0600"

  # HashiCorp Vault secrets
  # - name: DB_PASSWORD
  #   source: vault
  #   vaultPath: secret/data/myapp
  #   vaultKey: password
  #   vaultMount: secret

# =============================================================================
# PROVIDERS
# =============================================================================
providers:
  # ---------------------------------------------------------------------------
  # Fly.io - Cloud deployment
  # ---------------------------------------------------------------------------
  fly:
    region: sjc                # Fly.io region (sjc, ord, iad, ams, etc.)
    autoStopMachines: true     # Auto-suspend when idle (cost savings)
    autoStartMachines: true    # Auto-resume on connection
    cpuKind: shared            # shared (cost-effective) or performance (dedicated)
    sshPort: 10022             # External SSH port
    organization: personal     # Fly.io organization
    highAvailability: false    # Enable for multi-machine redundancy

  # ---------------------------------------------------------------------------
  # VS Code Remote SSH (Fly.io)
  # ---------------------------------------------------------------------------
  # Connect to your Fly.io deployment from VS Code using Remote SSH extension:
  #
  # 1. Ensure AUTHORIZED_KEYS secret is set (see secrets section above)
  #
  # 2. Add to ~/.ssh/config on your local machine:
  #    Host sindri-fly
  #        HostName <app-name>.fly.dev
  #        Port 10022
  #        User developer
  #        IdentityFile ~/.ssh/id_ed25519
  #        TCPKeepAlive yes
  #        ServerAliveInterval 30
  #        ServerAliveCountMax 6
  #        Compression yes
  #        ControlMaster auto
  #        ControlPath ~/.ssh/master-%r@%h:%p
  #        ControlPersist 600
  #
  # 3. In VS Code: Cmd+Shift+P -> "Remote-SSH: Connect to Host" -> sindri-fly
  #
  # Alternative: Use flyctl proxy if direct SSH is blocked:
  #    flyctl proxy 10022:2222 -a <app-name>
  #    Then connect to localhost:10022 instead
  #
  # See: docs/providers/FLY.md for detailed setup instructions

  # ---------------------------------------------------------------------------
  # Docker - Local container deployment
  # ---------------------------------------------------------------------------
  docker:
    network: bridge            # bridge, host, or none
    restart: unless-stopped    # no, always, on-failure, unless-stopped
    # ports:                   # Additional port mappings
    #   - "3000:3000"
    #   - "8080:8080"
    # privileged: false        # Run in privileged mode (use with caution)
    # extraHosts:              # Add entries to /etc/hosts
    #   - "host.docker.internal:host-gateway"

  # ---------------------------------------------------------------------------
  # DevPod - Multi-provider DevContainer deployment
  # ---------------------------------------------------------------------------
  # devpod:
  #   type: docker             # docker, aws, gcp, azure, digitalocean, kubernetes, ssh
  #   # buildRepository: ghcr.io/myorg/sindri  # Required for cloud/k8s providers
  #
  #   # AWS EC2 options
  #   # aws:
  #   #   region: us-west-2
  #   #   instanceType: c5.xlarge
  #   #   diskSize: 40
  #   #   useSpot: false
  #   #   subnetId: subnet-xxx
  #   #   securityGroupId: sg-xxx
  #
  #   # GCP Compute Engine options
  #   # gcp:
  #   #   project: my-project-id
  #   #   zone: us-central1-a
  #   #   machineType: e2-standard-4
  #   #   diskSize: 40
  #   #   diskType: pd-balanced  # pd-standard, pd-balanced, pd-ssd
  #
  #   # Azure VM options
  #   # azure:
  #   #   subscription: xxx-xxx-xxx
  #   #   resourceGroup: devpod-resources
  #   #   location: eastus
  #   #   vmSize: Standard_D4s_v3
  #   #   diskSize: 40
  #
  #   # DigitalOcean Droplet options
  #   # digitalocean:
  #   #   region: nyc3
  #   #   size: s-4vcpu-8gb
  #
  #   # Kubernetes pod options
  #   # kubernetes:
  #   #   namespace: devpod
  #   #   context: my-cluster
  #   #   storageClass: standard
  #   #   nodeSelector:
  #   #     kubernetes.io/arch: amd64
  #
  #   # SSH to existing machine
  #   # ssh:
  #   #   host: dev-server.example.com
  #   #   user: root
  #   #   port: 22
  #   #   keyPath: ~/.ssh/id_rsa

  # ---------------------------------------------------------------------------
  # Local Kubernetes cluster (kind/k3d)
  # ---------------------------------------------------------------------------
  # k8s:
  #   provider: kind           # kind or k3d
  #   clusterName: sindri-dev  # Defaults to sindri.yaml name
  #   version: v1.31.0
  #   nodes: 1                 # 1 = single node, >1 = multi-node with workers
  #
  #   # kind-specific options
  #   # kind:
  #   #   image: kindest/node:v1.31.0
  #   #   configFile: kind-config.yaml
  #
  #   # k3d-specific options
  #   # k3d:
  #   #   image: rancher/k3s:v1.31.0-k3s1
  #   #   registry:
  #   #     enabled: true
  #   #     name: k3d-registry
  #   #     port: 5000

  # ---------------------------------------------------------------------------
  # Kubernetes (native) - Note: use DevPod for K8s deployment
  # ---------------------------------------------------------------------------
  kubernetes:
    namespace: default
    storageClass: standard
    ingress:
      enabled: false
      hostname: ""
EOYAML

    print_success "Created sindri.yaml"
    echo ""
    echo "Reference files:"
    echo "  • docker/lib/profiles.yaml  - Extension profiles and their contents"
    echo "  • docker/lib/registry.yaml  - All available extensions"
    echo "  • docs/CONFIGURATION.md     - Full configuration guide"
    echo "  • examples/                 - Ready-to-use examples by provider"
    echo ""
    echo "Next steps:"
    echo "  1. Edit sindri.yaml to customize your deployment"
    echo "  2. Run: ./cli/sindri config validate"
    echo "  3. Run: ./cli/sindri deploy"
    echo ""
    echo "Quick commands:"
    echo "  • List profiles:    ./cli/extension-manager list-profiles"
    echo "  • List extensions:  ./cli/extension-manager list"
    echo "  • Validate config:  ./cli/sindri config validate"
    echo ""
}

# Validate configuration
config_validate() {
    local config="${1:-sindri.yaml}"

    if [[ ! -f "$config" ]]; then
        print_error "$config not found"
        return 1
    fi

    # Validate against schema
    local schema="$BASE_DIR/docker/lib/schemas/sindri.schema.json"
    if [[ -f "$schema" ]]; then
        validate_yaml_schema "$config" "$schema"
    fi

    print_success "Configuration valid"
}

# Deploy to provider
deploy() {
    local provider="${1:-}"
    local rebuild="${2:-}"
    local config="${3:-sindri.yaml}"

    if [[ ! -f "$config" ]]; then
        print_error "$config not found. Run: sindri config init"
        return 1
    fi

    # Use provider from config if not specified via command line
    if [[ -z "$provider" ]]; then
        provider=$(yq '.deployment.provider' "$config" 2>/dev/null || echo "docker")
    fi

    print_header "Deploying with $provider provider"

    # Export rebuild flag for adapters to use
    export SINDRI_REBUILD="$rebuild"

    case "$provider" in
        docker)
            "$BASE_DIR/deploy/adapters/docker-adapter.sh" deploy $rebuild "$config"
            ;;
        fly)
            "$BASE_DIR/deploy/adapters/fly-adapter.sh" deploy $rebuild "$config"
            ;;
        devpod)
            "$BASE_DIR/deploy/adapters/devpod-adapter.sh" deploy $rebuild "$config"
            ;;
        *)
            print_error "Unknown provider: $provider"
            echo "Available providers: docker, fly, devpod"
            return 1
            ;;
    esac
}

# Connect to instance
connect() {
    local config="${1:-sindri.yaml}"

    if [[ ! -f "$config" ]]; then
        print_error "$config not found"
        return 1
    fi

    local provider
    provider=$(yq '.deployment.provider' "$config")

    case "$provider" in
        docker)
            "$BASE_DIR/deploy/adapters/docker-adapter.sh" connect "$config"
            ;;
        fly)
            "$BASE_DIR/deploy/adapters/fly-adapter.sh" connect "$config"
            ;;
        devpod)
            "$BASE_DIR/deploy/adapters/devpod-adapter.sh" connect "$config"
            ;;
        *)
            print_error "Unknown provider: $provider"
            ;;
    esac
}

# Destroy deployment
destroy() {
    local provider="${1:-}"
    local force="${2:-}"
    local config="${3:-sindri.yaml}"

    if [[ ! -f "$config" ]]; then
        print_error "$config not found"
        return 1
    fi

    if [[ -z "$provider" ]]; then
        provider=$(yq '.deployment.provider' "$config" 2>/dev/null || echo "docker")
    fi

    local force_arg=""
    [[ "$force" == "--force" ]] && force_arg="--force"

    case "$provider" in
        docker)
            "$BASE_DIR/deploy/adapters/docker-adapter.sh" destroy "$force_arg" "$config"
            ;;
        fly)
            "$BASE_DIR/deploy/adapters/fly-adapter.sh" destroy "$force_arg" "$config"
            ;;
        devpod)
            "$BASE_DIR/deploy/adapters/devpod-adapter.sh" destroy "$force_arg" "$config"
            ;;
        *)
            print_error "Unknown provider: $provider"
            echo "Available providers: docker, fly, devpod"
            return 1
            ;;
    esac
}

# Run test suite on deployed instance
test_suite() {
    local config="${1:-sindri.yaml}"
    local suite="${2:-smoke}"

    if [[ ! -f "$config" ]]; then
        print_error "$config not found"
        return 1
    fi

    local name provider
    name=$(yq '.name' "$config")
    provider=$(yq '.deployment.provider' "$config")

    print_header "Running test suite: $suite on $name ($provider)"

    case "$suite" in
        smoke)
            # Basic connectivity and health checks
            print_status "Running smoke tests..."

            case "$provider" in
                docker)
                    # Check container is running
                    if ! docker ps | grep -q "$name"; then
                        print_error "Container $name is not running"
                        return 1
                    fi

                    # Check basic commands work
                    docker exec "$name" whoami || { print_error "Failed to exec into container"; return 1; }
                    docker exec "$name" cat /etc/os-release || { print_error "Failed to read OS info"; return 1; }
                    ;;
                fly)
                    # Check app is running
                    if ! flyctl status -a "$name" 2>/dev/null | grep -q "running"; then
                        print_error "Fly.io app $name is not running"
                        return 1
                    fi

                    # Check SSH connectivity
                    flyctl ssh console -a "$name" -C "whoami" || { print_error "SSH test failed"; return 1; }
                    ;;
                devpod)
                    # Check workspace exists
                    if ! devpod list | grep -q "$name"; then
                        print_error "DevPod workspace $name not found"
                        return 1
                    fi

                    # Check SSH connectivity
                    devpod ssh "$name" "whoami" || { print_error "SSH test failed"; return 1; }
                    ;;
                *)
                    print_error "Smoke tests not implemented for provider: $provider"
                    return 1
                    ;;
            esac

            print_success "Smoke tests passed"
            ;;
        integration)
            # Full integration tests
            print_status "Running integration tests..."

            # Deploy if not already running
            if ! deploy "" "" "$config"; then
                print_error "Deploy failed"
                return 1
            fi

            # Run extension validation
            case "$provider" in
                docker)
                    docker exec "$name" /docker/cli/extension-manager validate-all
                    ;;
                fly)
                    flyctl ssh console -a "$name" -C "/docker/cli/extension-manager validate-all"
                    ;;
                devpod)
                    devpod ssh "$name" "/docker/cli/extension-manager validate-all"
                    ;;
                *)
                    print_error "Integration tests not implemented for provider: $provider"
                    return 1
                    ;;
            esac

            print_success "Integration tests passed"
            ;;
        full)
            # Run all test suites
            print_status "Running full test suite..."
            test_suite "$config" "smoke" || return 1
            test_suite "$config" "integration" || return 1
            print_success "Full test suite passed"
            ;;
        *)
            print_error "Unknown test suite: $suite"
            echo "Available suites: smoke, integration, full"
            return 1
            ;;
    esac
}

# Show deployment plan
plan() {
    local config="${1:-sindri.yaml}"

    if [[ ! -f "$config" ]]; then
        print_error "$config not found"
        return 1
    fi

    local provider
    provider=$(yq '.deployment.provider' "$config")

    case "$provider" in
        docker)
            "$BASE_DIR/deploy/adapters/docker-adapter.sh" plan "$config"
            ;;
        fly)
            "$BASE_DIR/deploy/adapters/fly-adapter.sh" plan "$config"
            ;;
        devpod)
            "$BASE_DIR/deploy/adapters/devpod-adapter.sh" plan "$config"
            ;;
        *)
            print_error "Unknown provider: $provider"
            ;;
    esac
}

# Show deployment status
status() {
    local config="${1:-sindri.yaml}"

    if [[ ! -f "$config" ]]; then
        print_error "$config not found"
        return 1
    fi

    local provider
    provider=$(yq '.deployment.provider' "$config")

    case "$provider" in
        docker)
            "$BASE_DIR/deploy/adapters/docker-adapter.sh" status "$config"
            ;;
        fly)
            "$BASE_DIR/deploy/adapters/fly-adapter.sh" status "$config"
            ;;
        devpod)
            "$BASE_DIR/deploy/adapters/devpod-adapter.sh" status "$config"
            ;;
        *)
            print_error "Unknown provider: $provider"
            ;;
    esac
}

# Main
main() {
    local command="${1:-help}"
    shift || true

    case "$command" in
        deploy)
            local provider=""
            local rebuild=""
            local config="sindri.yaml"
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    -p|--provider)
                        provider="$2"
                        shift 2
                        ;;
                    -r|--rebuild)
                        rebuild="--rebuild"
                        shift
                        ;;
                    -c|--config)
                        config="$2"
                        shift 2
                        ;;
                    *)
                        shift
                        ;;
                esac
            done
            deploy "$provider" "$rebuild" "$config"
            ;;
        connect)
            local config="sindri.yaml"
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    -c|--config)
                        config="$2"
                        shift 2
                        ;;
                    *)
                        shift
                        ;;
                esac
            done
            connect "$config"
            ;;
        destroy)
            local provider=""
            local force=""
            local config="sindri.yaml"
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    -p|--provider)
                        provider="$2"
                        shift 2
                        ;;
                    -f|--force)
                        force="--force"
                        shift
                        ;;
                    -c|--config)
                        config="$2"
                        shift 2
                        ;;
                    *)
                        shift
                        ;;
                esac
            done
            destroy "$provider" "$force" "$config"
            ;;
        status)
            local config="sindri.yaml"
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    -c|--config) config="$2"; shift 2 ;;
                    *) shift ;;
                esac
            done
            status "$config"
            ;;
        plan)
            local config="sindri.yaml"
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    -c|--config)
                        config="$2"
                        shift 2
                        ;;
                    *)
                        shift
                        ;;
                esac
            done
            plan "$config"
            ;;
        test)
            local config="sindri.yaml"
            local suite="smoke"
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    -c|--config)
                        config="$2"
                        shift 2
                        ;;
                    -s|--suite)
                        suite="$2"
                        shift 2
                        ;;
                    *)
                        shift
                        ;;
                esac
            done
            test_suite "$config" "$suite"
            ;;
        config)
            case "${1:-}" in
                init)
                    config_init
                    ;;
                validate)
                    shift
                    local config="sindri.yaml"
                    while [[ $# -gt 0 ]]; do
                        case "$1" in
                            -c|--config)
                                config="$2"
                                shift 2
                                ;;
                            *)
                                config="$1"
                                shift
                                ;;
                        esac
                    done
                    config_validate "$config"
                    ;;
                *)
                    echo "Usage: sindri config <init|validate>"
                    ;;
            esac
            ;;
        profiles)
            case "${1:-}" in
                list)
                    "$BASE_DIR/cli/extension-manager" list-profiles
                    ;;
                show)
                    [[ -z "${2:-}" ]] && echo "Usage: sindri profiles show <name>" && exit 1
                    yq ".profiles.\"$2\"" "$BASE_DIR/docker/lib/profiles.yaml"
                    ;;
                *)
                    echo "Usage: sindri profiles <list|show>"
                    ;;
            esac
            ;;
        secrets)
            # Source secrets manager
            source "$BASE_DIR/cli/secrets-manager"

            case "${1:-}" in
                validate)
                    secrets_validate "${2:-sindri.yaml}"
                    ;;
                list)
                    secrets_list "${2:-sindri.yaml}"
                    ;;
                test-vault)
                    secrets_test_vault
                    ;;
                encode-file)
                    [[ -z "${2:-}" ]] && echo "Usage: sindri secrets encode-file <path>" && exit 1
                    secrets_encode_file "$2"
                    ;;
                *)
                    echo "Usage: sindri secrets <validate|list|test-vault|encode-file>"
                    ;;
            esac
            ;;
        k8s)
            # Local Kubernetes cluster management
            local k8s_cmd="${1:-help}"
            shift || true

            local provider="" name="" force="" config=""
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    -p|--provider)
                        provider="$2"
                        shift 2
                        ;;
                    -n|--name)
                        name="$2"
                        shift 2
                        ;;
                    -f|--force)
                        force="--force"
                        shift
                        ;;
                    -c|--config)
                        config="$2"
                        shift 2
                        ;;
                    *)
                        # Check if it's a config file
                        if [[ -f "$1" ]]; then
                            config="$1"
                        fi
                        shift
                        ;;
                esac
            done

            # Build adapter args
            local adapter_args=("$k8s_cmd")
            [[ -n "$provider" ]] && adapter_args+=("--provider" "$provider")
            [[ -n "$name" ]] && adapter_args+=("--name" "$name")
            [[ -n "$force" ]] && adapter_args+=("$force")
            [[ -n "$config" ]] && adapter_args+=("$config")

            # Execute k8s adapter
            "$BASE_DIR/deploy/adapters/k8s/k8s-adapter.sh" "${adapter_args[@]}"
            ;;
        backup)
            # Delegate to backup-restore script
            "$BASE_DIR/cli/backup-restore" backup "$@"
            ;;
        restore)
            # Delegate to backup-restore script
            "$BASE_DIR/cli/backup-restore" restore "$@"
            ;;
        help|-h|--help)
            show_help
            ;;
        version|-V|--version)
            show_version
            ;;
        *)
            print_error "Unknown command: $command"
            show_help
            exit 1
            ;;
    esac
}

main "$@"
